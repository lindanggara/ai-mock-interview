{
  "Keahlian Teknis & Background": {
    "question": "Jelaskan pengalaman Anda dalam menggunakan Python dan library Data Science (pandas, numpy, scikit-learn). Berikan contoh proyek spesifik yang pernah Anda kerjakan.",
    "keywords": [
      "python",
      "pandas",
      "numpy",
      "scikit-learn",
      "tensorflow",
      "pytorch",
      "data",
      "model",
      "proyek",
      "pengalaman",
      "implementasi",
      "analisis",
      "pipeline",
      "data pipeline",
      "script",
      "automation",
      "notebook",
      "jupyter",
      "function",
      "class",
      "modular",
      "debugging",
      "optimization",
      "preprocessing",
      "cleaning",
      "wrangling",
      "ETL",
      "transformasi",
      "merge",
      "join",
      "groupby",
      "filtering",
      "encoding",
      "normalisasi",
      "standardisasi"
    ],
    "ideal_length": [100, 250],
    "weight": {
      "technical": 0.4,
      "depth": 0.3,
      "structure": 0.3
    }
  },
  "Pengetahuan Statistik": {
    "question": "Bagaimana Anda menjelaskan perbedaan antara supervised learning dan unsupervised learning kepada stakeholder non-teknis? Berikan contoh use case masing-masing.",
    "keywords": [
      "supervised",
      "unsupervised",
      "machine learning",
      "klasifikasi",
      "regresi",
      "clustering",
      "model",
      "prediksi",
      "contoh",
      "use case",
      "stakeholder",
      "label",
      "berlabel",
      "training data",
      "target",
      "output",
      "tanpa label",
      "pola",
      "grouping",
      "dimensionality reduction",
      "pca",
      "analogi",
      "sederhana",
      "contoh nyata",
      "spam detection",
      "fraud detection",
      "sentiment analysis",
      "customer segmentation",
      "anomaly detection",
      "topic modeling",
      "cluster",
      "feature",
      "algoritma"

    ],
    "ideal_length": [80, 200],
    "weight": {
      "technical": 0.3,
      "depth": 0.3,
      "structure": 0.4
    }
  },
  "Data Wrangling & EDA": {
    "question": "Ceritakan pengalaman Anda dalam melakukan data cleaning dan exploratory data analysis (EDA). Apa tantangan terbesar yang Anda hadapi dan bagaimana Anda mengatasinya?",
    "keywords": [
      "cleaning",
      "missing values",
      "outlier",
      "visualisasi",
      "eda",
      "exploratory",
      "kualitas data",
      "preprocessing",
      "tantangan",
      "solusi",
      "imputasi",
      "data quality",
      "data profiling",
      "inconsistent format",
      "duplicate data",
      "noise",
      "normalisasi",
      "standardisasi",
      "encoding",
      "data type correction",
      "mcar",
      "mar",
      "mnar",
      "knn imputation",
      "median imputation",
      "interpolation",
      "iqr method",
      "z-score",
      "distribution",
      "correlation",
      "heatmap",
      "boxplot",
      "histogram",
      "pattern detection",
      "trend analysis",
      "seasonality",
      "pandas profiling",
      "matplotlib",
      "seaborn",
      "plotly",
      "multisource data",
      "data inconsistency",
      "schema mismatch",
      "anomaly detection",
      "root cause analysis",
      "iterative analysis",
      "validation",
      "documentation"

    ],
    "ideal_length": [100, 250],
    "weight": {
      "technical": 0.35,
      "depth": 0.35,
      "structure": 0.3
    }
  },
  "Problem Solving & Studi Kasus": {
    "question": "Bayangkan Anda diminta untuk membuat model prediksi churn pelanggan. Jelaskan langkah-langkah yang akan Anda ambil dari awal hingga deployment ke production.",
    "keywords": [
      "churn",
      "prediksi",
      "model",
      "feature engineering",
      "evaluasi",
      "metrik",
      "deployment",
      "dampak bisnis",
      "langkah",
      "proses",
      "pipeline",
      "normalisasi",
      "standardisasi",
      "encoding",
      "transformasi",
      "scaling",
      "deduplikasi",
      "noise",
      "inkonsistensi",
      "data corrupt",
      "univariate",
      "bivariate",
      "multivariate",
      "boxplot",
      "histogram",
      "scatter plot",
      "correlation",
      "heatmap",
      "distribution analysis",
      "data merging",
      "data profiling",
      "validasi",
      "root cause analysis",
      "pandas profiling",
      "matplotlib",
      "seaborn"

    ],
    "ideal_length": [150, 300],
    "weight": {
      "technical": 0.3,
      "depth": 0.4,
      "structure": 0.3
    }
  },
  "Pemahaman Bisnis": {
    "question": "Bagaimana Anda memastikan bahwa model machine learning yang Anda buat memberikan nilai kepada bisnis? Berikan contoh metrik atau cara pengukuran yang Anda gunakan.",
    "keywords": [
      "nilai bisnis",
      "roi",
      "dampak",
      "metric",
      "kpi",
      "stakeholder",
      "keputusan",
      "actionable",
      "contoh",
      "pengukuran",
      "cost benefit",
      "business impact",
      "value creation",
      "profitability",
      "revenue lift",
      "cost reduction",
      "efficiency improvement",
      "operational impact",
      "conversion rate",
      "engagement rate",
      "retention",
      "churn reduction",
      "average order value",
      "lifetime value",
      "customer acquisition cost",
      "a/b testing",
      "experiment",
      "baseline comparison",
      "uplift analysis",
      "impact measurement",
      "business metrics tracking",
      "monitoring",
      "model performance",
      "drift detection",
      "alerting",
      "benchmarking",
      "business requirement",
      "alignment",
      "feedback loop",
      "decision support",
      "scenario analysis",
      "forecasting"

    ],
    "ideal_length": [80, 200],
    "weight": {
      "technical": 0.25,
      "depth": 0.35,
      "structure": 0.4
    }
  },
  "Komunikasi & Kolaborasi": {
    "question": "Jelaskan pengalaman Anda dalam mengkomunikasikan hasil analisis data kepada tim non-teknis. Bagaimana cara Anda menyederhanakan konsep yang kompleks?",
    "keywords": [
      "komunikasi",
      "visualisasi",
      "presentasi",
      "stakeholder",
      "menjelaskan",
      "sederhana",
      "storytelling",
      "dashboard",
      "non-teknis",
      "audiens",
      "simplifikasi",
      "analogi",
      "penyederhanaan",
      "bahasa awam",
      "tanpa jargon",
      "intuitif",
      "narasi",
      "alur cerita",
      "insight",
      "pesan utama",
      "highlight",
      "komunikasi efektif",
      "grafik",
      "chart",
      "infografis",
      "heatmap",
      "tableau",
      "power bi",
      "plotly",
      "visual storytelling",
      "interpretasi",
      "temuan",
      "rekomendasi",
      "kesimpulan",
      "actionable insight",
      "feedback",
      "diskusi",
      "kolaborasi",
      "alignment",
      "decision making",
      "non-technical team"

    ],
    "ideal_length": [80, 200],
    "weight": {
      "technical": 0.2,
      "depth": 0.3,
      "structure": 0.5
    }
  },
  "Evaluasi & Optimasi Model": {
    "question": "Jelaskan metode yang Anda gunakan untuk mengevaluasi performa model dan melakukan hyperparameter tuning. Bagaimana cara Anda menghindari overfitting?",
    "keywords": [
      "evaluasi",
      "cross-validation",
      "metric",
      "akurasi",
      "precision",
      "recall",
      "hyperparameter",
      "tuning",
      "overfitting",
      "regularisasi",
      "grid search",
      "validation",
      "test set",
      "train test split",
      "holdout",
      "stratified",
      "confusion matrix",
      "roc auc",
      "f1 score",
      "mae",
      "rmse",
      "loss function",
      "bias variance",
      "k-fold",
      "stratified k-fold",
      "nested cross-validation",
      "cv score",
      "random search",
      "bayesian optimization",
      "optuna",
      "early stopping",
      "learning rate",
      "lambda",
      "alpha",
      "dropout",
      "tuning parameter",
      "data augmentation",
      "ridge",
      "lasso",
      "model complexity",
      "pruning",
      "ensemble",
      "bagging",
      "boosting",
      "learning curve",
      "validation curve",
      "epoch",
      "training loss",
      "validation loss"

    ],
    "ideal_length": [100, 250],
    "weight": {
      "technical": 0.45,
      "depth": 0.35,
      "structure": 0.2
    }
  },
  "Big Data & Skalabilitas": {
    "question": "Ceritakan pengalaman Anda bekerja dengan dataset skala besar. Tools dan teknik apa yang Anda gunakan untuk mengatasi masalah skalabilitas?",
    "keywords": [
      "big data",
      "spark",
      "hadoop",
      "distributed",
      "skalabilitas",
      "performa",
      "optimasi",
      "parallel processing",
      "cluster",
      "memory management",
      "distributed computing",
      "cluster management",
      "fault tolerance",
      "data partitioning",
      "caching",
      "in-memory computation",
      "parallelism",
      "batch processing",
      "pipeline optimization",
      "data ingestion",
      "resource allocation",
      "scalability testing",
      "job scheduling",
      "ETL",
      "data replication"
    ],
    "ideal_length": [100, 250],
    "weight": {
      "technical": 0.4,
      "depth": 0.35,
      "structure": 0.25
    }
  },
  "Etika & Bias dalam AI": {
    "question": "Bagaimana Anda mengidentifikasi dan mengatasi bias dalam model machine learning? Berikan contoh dari pengalaman Anda atau pendekatan yang akan Anda gunakan.",
    "keywords": [
      "bias",
      "fairness",
      "etika",
      "diskriminasi",
      "protected attributes",
      "demographic parity",
      "keadilan model",
      "mitigasi bias",
      "ethical ai",
      "algorithmic bias",
      "fairness metrics",
      "equal opportunity",
      "reweighting",
      "resampling",
      "threshold adjustment",
      "adversarial debiasing",
      "bias detection",
      "transparency",
      "accountability",
      "ethical considerations",
      "protected groups",
      "sensitive attributes",
      "model auditing",
      "data ethics"

    ],
    "ideal_length": [80, 200],
    "weight": {
      "technical": 0.3,
      "depth": 0.4,
      "structure": 0.3
    }
  },
  "MLOps & Deployment": {
    "question": "Jelaskan pengalaman Anda dalam deploy model machine learning ke production. Apa saja pertimbangan dan tantangan yang Anda hadapi?",
    "keywords": [
      "deployment",
      "production",
      "mlops",
      "monitoring",
      "api",
      "docker",
      "kubernetes",
      "ci/cd",
      "versioning",
      "model serving",
      "skalabilitas",
      "continuous integration",
      "continuous deployment",
      "containerization",
      "orchestration",
      "load balancing",
      "auto-scaling",
      "model monitoring",
      "model retraining",
      "A/B testing",
      "blue-green deployment",
      "canary deployment",
      "latency optimization",
      "resource allocation",
      "model rollback",
      "inference pipeline"
    ],
    "ideal_length": [120, 280],
    "weight": {
      "technical": 0.35,
      "depth": 0.35,
      "structure": 0.3
    }
  }
}
